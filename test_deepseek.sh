#!/bin/bash
# Quick test script for DeepSeek-OCR server (vLLM-based)

echo "ğŸ§ª Testing DeepSeek-OCR Server (vLLM)"
echo "======================================"
echo ""

# Check if server is running
echo "1ï¸âƒ£ Checking server health..."
response=$(curl -s http://localhost:5003/health)
echo "$response" | python3 -m json.tool 2>/dev/null || echo "$response"
echo ""

# Check status
if echo "$response" | grep -q '"model_loaded":true'; then
    echo "âœ… Server is ready!"
    echo ""
    echo "2ï¸âƒ£ You can now:"
    echo "   - Configure iOS app Settings â†’ Server URLs"
    echo "   - Set DeepSeek-OCR URL to: http://localhost:5003"
    echo "   - Start scanning receipts!"
    echo ""
    echo "ğŸš€ Using vLLM for optimized inference"
    echo "âš¡ Batch processing supported and recommended"
elif echo "$response" | grep -q '"model_loaded":false'; then
    echo "â³ Server is running but model is still loading..."
    echo ""
    echo "ğŸ’¡ First time setup downloads ~8GB model (takes 3-5 minutes)"
    echo "   vLLM will compile kernels on first run"
    echo ""
    echo "   Wait and run this script again: ./test_deepseek.sh"
else
    echo "âŒ Server is not responding"
    echo ""
    echo "ğŸ’¡ Start the server with: ./start_deepseek.sh"
    echo "âš ï¸  Remember: vLLM requires Linux + CUDA GPU"
fi

echo ""
echo "ğŸ“Š Server Info:"
echo "   - Engine: $(echo "$response" | grep -o '"engine":"[^"]*"')"
echo "   - Model: $(echo "$response" | grep -o '"model":"[^"]*"')"



