# Dockerfile for DeepSeek-OCR Server using vLLM official image
# Build date: 2025-10-26

FROM vllm/vllm-openai:latest

# Clean up to make space, then install vLLM nightly for DeepSeek-OCR
RUN pip cache purge && \
    rm -rf /root/.cache/pip && \
    pip install --no-cache-dir --upgrade vllm --pre --extra-index-url https://wheels.vllm.ai/nightly && \
    pip cache purge

# Install Flask and dependencies
RUN pip install --no-cache-dir --ignore-installed blinker flask pillow

# Set working directory
WORKDIR /app

# Copy server code
COPY deepseek_ocr_server.py /app/

# Expose port
EXPOSE 5003

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:5003/health || exit 1

# Override vLLM's default ENTRYPOINT to run our Flask server
ENTRYPOINT []
CMD ["python3", "/app/deepseek_ocr_server.py"]


